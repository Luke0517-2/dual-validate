trigger:
  - newman-test

pool:
  vmImage: 'ubuntu-latest'

variables:
  dual-validate-postman-script: CHT_MOrder_Dual-validate.postman_collection.json
  baseUrl: http://dualvalidateservice-istio-system.apps.ocp.iisi.test/v0
  floderName: wildflyVerifyUnLoadDataExe
  loopTimes : 2


stages:
- stage: dual_validate_newman
  displayName: dual_validate_newman
  jobs:
  - job: dual_validate_newman
    displayName: dual_validate_newman
    timeoutInMinutes: 360 # how long to run the job before automatically cancelling
    steps:
      # 主機環境設定
      - task: Bash@3
        inputs:
          targetType: 'inline'
          script: |
            sudo -- sh -c "echo '60.250.171.28    oauth-openshift.apps.ocp.iisi.test' >> /etc/hosts"
            sudo -- sh -c "echo '60.250.171.28    api.ocp.iisi.test' >> /etc/hosts"
            sudo -- sh -c "echo '60.250.171.28    dual-validate-d210641.apps.ocp.iisi.test' >> /etc/hosts"
            sudo -- sh -c "echo '60.250.171.28    dualvalidateservice-istio-system.apps.ocp.iisi.test' >> /etc/hosts"
            
            echo 'hosts檔案內容'
            cat /etc/hosts
            
            echo '目前路徑'
            pwd
            
            export BUILD_NUMBER=$(Build.BuildNumber)
            echo 'build 編號  #'${BUILD_NUMBER}
            
            timedatectl
            echo 'set timezone to Asia/Taipei'
            sudo timedatectl set-timezone Asia/Taipei
            timedatectl
            
            echo '產生結果報表放置的目錄'
            mkdir $(Build.SourcesDirectory)/report
            echo $(Build.SourcesDirectory)/report

            mkdir $(Build.SourcesDirectory)/logs
        displayName: 'set env'

      - task: NodeTool@0
        inputs:
          versionSpec: '16.x'

      - script: |
          npm install -g newman
          npm install -g newman-reporter-html
        displayName: 'install newman'
        
           
      - task: Bash@3
        inputs:
          targetType: 'inline'
          script: |

            date1=$(date +%Y%m%d)                # 今天的日期
            fileName=$(floderName)_${date1}      # 設定檔名
            # 在電話前後加入雙引號
            #sed -i -e 's/^0/"0/g' $(Build.SourcesDirectory)/$(floderName)/${fileName}.csv
            #sed -i -e 's/,/",/g' $(Build.SourcesDirectory)/$(floderName)/${fileName}.csv

            str1='"telNum","custId"'
            str2=$(sed -n '1,1p' $(Build.SourcesDirectory)/$(floderName)/${fileName}.csv)
            echo 變數名 : ${str1}
            echo 檔案表頭名 : ${str2}
            if [ ${str1} = ${str2} ]
            then
              echo '不須修改檔案';
            else
              echo '添加header'
              sed -i -e '1i"telNum","custId"' $(Build.SourcesDirectory)/$(floderName)/${fileName}.csv
            fi
            
            echo ----------$fileName---------------
            echo "##vso[task.setvariable variable=FILE_NAME;issecret=false]$fileName"

        displayName:  'check date&fileName'  

      - task: Bash@3
        inputs:
          targetType: 'inline'
          script: |
            echo ----$(FILE_NAME)----------- 
        displayName: 'inspect fileName'
        continueOnError: true


      - task: Bash@3
        inputs:
          targetType: 'inline'
          script: |

            echo '開始進行驗證測試，會重新統計報表'
            UUID=$(curl -s '$(baseUrl)/cht/validate/startTest' | jq -r '.uuid')
            echo  $UUID

            echo '透過聯單號碼取得既有系統的聯單並進行新舊查核機制比對'
            newman run $(Build.SourcesDirectory)/$(dual-validate-postman-script) --env-var="baseUrl=$(baseUrl)" -d $(Build.SourcesDirectory)/$(floderName)/$(FILE_NAME).csv --global-var="uuid=$UUID" --folder 透過聯單號碼取得既有系統的聯單並進行新舊查核機制比對
            
            echo '取得現行統計報表，產出Zip檔案'            
            var0=`ls $(Build.SourcesDirectory)/report | wc -l`
            for i in {1..$(loopTimes)}
            do
                    echo $i 'time'
                    if [[ $var0 -eq 1 ]]
                    then
                            echo 'success download'
                            break
                    fi
                    curl -I -v --trace-time --max-time 7200 --connect-timeout 7200 -o $(Build.SourcesDirectory)/report/report.zip --request GET -H "uuid: $UUID" '$(baseUrl)/cht/validate/currentReportWithZip'
            done

            echo '成功執行'
        continueOnError: false
        displayName: '執行雙軌驗證'

      - task: PublishPipelineArtifact@1
        continueOnError: true
        inputs:
          targetPath: $(Build.SourcesDirectory)/report
          artifact: 'report'
        displayName: '上傳 report'
        
      - task: Bash@3
        inputs:
          targetType: 'inline'
          script: |
            echo '清除目前的驗證測試，會清空相關測試資料'
            curl -v --trace-time --max-time 3600 --connect-timeout 3600 --request GET -H "uuid: $UUID" '$(baseUrl)/cht/validate/stopTest'
        displayName:  'stop test'     

      - task: oc-setup@2
        inputs:
          openshiftService: 'ocp-4.11'
          version: '4.9.28'
        continueOnError: false 

      - script: |
          #切換ns
          oc project mbms-morder-feature

          #取得所有dual-validate的pod
          varPods=`kubectl get pod | grep dual-validate | awk '{print $1}'`

          count=0
          for i in $varPods; 
          do 
            #下載log
            echo generate $count"-logs"
            kubectl logs $i -c dual-validate > $(Build.SourcesDirectory)/logs/$count"-logs".txt
            #刪除pod，自動重啟
            echo delete "Pod" $i
            kubectl delete pod $i
            count=$(($count+1)) 
          done
        displayName:  'download log & delete pod' 

      - task: PublishPipelineArtifact@1
        continueOnError: true
        inputs:
          targetPath: $(Build.SourcesDirectory)/logs
          artifact: 'logs'
        displayName: '上傳 logs'          

